{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script mines tweets to train the model.\n",
    "\n",
    "Use my followers to get tweets, then say similar stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "should have already got credentials\n"
     ]
    }
   ],
   "source": [
    "#retweets tweets about the housing crisis\n",
    "\n",
    "# Import Tweepy, sleep, credentials.py\n",
    "import tweepy\n",
    "import time\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "import sys, os\n",
    "\n",
    "from authenticate import *\n",
    "\n",
    "api = get_authenticated_api()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify users to RT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "starting_user_set = api.friends(count=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could prune these people in a variety of ways. It might help to get a subset where some of them follow each other, then get the users that _they_ follow together and add them to the list. But this might be needlessly complex, so to start, let's just see what we can do with this group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify tweets from them that we actually want to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want:\n",
    "\n",
    " - Retweets only - MAYBE, maybe not. I am not sure. It might be OK to just generate random pro-housing slogans.\n",
    " - Tweets specific to housing. I would rather avoid a direct keyword approach. Something social, like where they're retweeting each other, might work.\n",
    " \n",
    "Other options:\n",
    "\n",
    " - Get those users' favorites using API.favorites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Get some users' tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting page 1 for statuses\n",
      "164\n",
      "Getting page 2 for statuses\n",
      "163\n",
      "Getting page 3 for statuses\n",
      "160\n",
      "Getting page 4 for statuses\n",
      "154\n",
      "Getting page 5 for statuses\n",
      "169\n",
      "Getting page 6 for statuses\n",
      "159\n",
      "Getting page 7 for statuses\n",
      "120\n",
      "Getting page 8 for statuses\n",
      "116\n",
      "Getting page 9 for statuses\n",
      "140\n",
      "Getting page 10 for statuses\n",
      "133\n",
      "Getting page 11 for statuses\n",
      "122\n",
      "Getting page 12 for statuses\n",
      "148\n",
      "Getting page 13 for statuses\n",
      "146\n",
      "Getting page 14 for statuses\n",
      "146\n",
      "Getting page 15 for statuses\n",
      "150\n",
      "Getting page 16 for statuses\n",
      "134\n",
      "Getting page 17 for statuses\n",
      "14\n",
      "number of statuses for user: 2338\n"
     ]
    }
   ],
   "source": [
    "user_statuses=[]\n",
    "page_count=0\n",
    "for status_page in tweepy.Cursor(\n",
    "        api.user_timeline, screen_name=\"curiouskiwicat\", include_rts=False, \n",
    "        tweet_mode='extended', count=200).pages():\n",
    "    page_count += 1\n",
    "    print(f'Getting page {page_count} for statuses')\n",
    "    print(len(status_page))\n",
    "    user_statuses.extend(status_page)\n",
    "print(f\"number of statuses for user: {len(user_statuses)}\")\n",
    "curiouskiwicat_statuses=user_statuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2019, 2, 8, 19, 24, 26)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s.created_at for s in curiouskiwicat_statuses[2008:2009]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1093953720679710720"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a tweet at the beginning of 2018\n",
    "curiouskiwicat_statuses[2008].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beginning_of_2018_marker=949099924330721280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def describe_status(s):\n",
    "    print(f\"TWEET by {s.user.screen_name}:\")\n",
    "    print(s.full_text)\n",
    "    #print(\", \".join(dir(s)))\n",
    "    print(f\"is_quote_status: {s.is_quote_status}\")\n",
    "    print(f\"in_reply_to_screen_name: {s.in_reply_to_screen_name}\")\n",
    "    print(\"___\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\",\".join(dir(user_retweets[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we need to look up the original tweet using the quoted_status_id..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get a set of user statuses that are retweets..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get this user's last 10 statuses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieval script to retrieve a set of tweets in my dictionary format and save to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#[print(susi.screen_name) for susi in starting_user_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users_to_retrieve = starting_user_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userids_to_retrieve=[utr.screen_name for utr in users_to_retrieve]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_users_tweets(user_ids_to_retrieve):\n",
    "    tweet_rt_pairs = []\n",
    "    \n",
    "    rls=api.rate_limit_status()\n",
    "    #record how much remaining status limit we have\n",
    "    status_rl_left = rls['resources']['statuses']['/statuses/show/:id']['remaining']\n",
    "    status_rl_rest_ts = rls['resources']['statuses']['/statuses/show/:id']['reset']\n",
    "    beginning_of_2018_marker=949099924330721280\n",
    "    \n",
    "    #time.sleep((datetime.fromtimestamp(rls['resources']['statuses']['/statuses/show/:id']['reset'])-datetime.now()).seconds)\n",
    "    for i, u in enumerate(user_ids_to_retrieve):\n",
    "        \n",
    "\n",
    "        \n",
    "        start= time.perf_counter()\n",
    "        print(f\"retrieving tweets for user {u}\")\n",
    "        print(status_rl_left)\n",
    "    \n",
    "        try:\n",
    "            user_statuses=[]\n",
    "            page_count=0\n",
    "            for status_page in tweepy.Cursor(\n",
    "                    api.user_timeline, screen_name=u, include_rts=False, \n",
    "                    tweet_mode='extended', count=200,since_id=beginning_of_2018_marker).pages(10):\n",
    "                page_count += 1\n",
    "                #print(f'Getting page {page_count} for statuses')\n",
    "                #print(len(status_page))\n",
    "                user_statuses.extend(status_page)\n",
    "            print(f\"number of statuses for user: {len(user_statuses)}\")\n",
    "        except tweepy.TweepError as tweep_error:\n",
    "            if tweep_error.args[0][0]['code']==34:\n",
    "                    print(\"somehow browsed through too many timeline pages. quitting\")\n",
    "                    continue\n",
    "            elif tweep_error.args[0]=='Not authorized.':\n",
    "                print(\"couldn't retrieve user tweets. moving on to next user.\")\n",
    "                continue\n",
    "            \n",
    "\n",
    "        user_retweets = [s for s in user_statuses if s.is_quote_status==True]\n",
    "        \n",
    "        print(f\"number of retweets for user: {len(user_retweets)}\")\n",
    "\n",
    "        for s in user_retweets:\n",
    "            \n",
    "            if status_rl_left<5:\n",
    "                #wait a while\n",
    "                #how long?\n",
    "                rls=api.rate_limit_status()\n",
    "                #double check that we are in fact almost out.\n",
    "                status_rl_left = rls['resources']['statuses']['/statuses/show/:id']['remaining']\n",
    "                \n",
    "                if status_rl_left<5:\n",
    "                    status_rl_rest_ts = rls['resources']['statuses']['/statuses/show/:id']['reset']\n",
    "                    seconds_to_wait = 1 + (datetime.fromtimestamp(status_rl_rest_ts)-datetime.now()).seconds\n",
    "                    print(f\"status limit almost reached. need to pause for {seconds_to_wait}\")\n",
    "                    time.sleep(seconds_to_wait)\n",
    "                \n",
    "            try:\n",
    "                if hasattr(s,'quoted_status_id'):\n",
    "                    status_rl_left-=1#subtract from our status limit.\n",
    "                    original_tweet = api.get_status(s.quoted_status_id,tweet_mode='extended')\n",
    "                else:\n",
    "                    print(\"tweet has not original status Id for some reason. ignoring.\")\n",
    "                    continue\n",
    "            except tweepy.TweepError as tweep_error:\n",
    "                try:\n",
    "                    if tweep_error.args[0][0]['code']==144:\n",
    "                        print(\"tweet not found, ignoring\")\n",
    "                        continue\n",
    "                    elif tweep_error.args[0][0]['code']==179:\n",
    "                        print(\"tweet access prohibited, ignoring\")\n",
    "                        continue\n",
    "                    elif tweep_error.args[0][0]['code']==63:\n",
    "                        print(\"user has been suspended\")\n",
    "                        continue\n",
    "                    elif tweep_error.args[0][0]['code']==34:\n",
    "                        print(\"spage error when trying to retrieve RT. continuing\")\n",
    "                        continue\n",
    "                    else:\n",
    "                        raise tweep_error\n",
    "                except Exception as e:\n",
    "                    print(\"error while handling exception. passing back exception.\")\n",
    "                    return(e)\n",
    "\n",
    "            #if the \n",
    "            retweet_data = {\n",
    "                'retweet_text':s.full_text,\n",
    "                'rt_author':s.user.screen_name,\n",
    "                'original_text':original_tweet.full_text,\n",
    "                'original_author':original_tweet.user.screen_name\n",
    "            }\n",
    "            #print(\"retweet of:\")\n",
    "            #describe_status(original_tweet)\n",
    "            tweet_rt_pairs = tweet_rt_pairs + [retweet_data]\n",
    "\n",
    "        end= time.perf_counter()\n",
    "        #iterate through a maximum of 1 user per second.\n",
    "        duration=end-start\n",
    "        if(duration<1):\n",
    "            time.sleep(1-duration)\n",
    "    return(tweet_rt_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieving tweets for user modernmultifam\n",
      "900\n",
      "number of statuses for user: 160\n",
      "number of retweets for user: 1\n",
      "retrieving tweets for user Cheryl_NZ\n",
      "899\n",
      "number of statuses for user: 509\n",
      "number of retweets for user: 3\n",
      "retrieving tweets for user Naithin\n",
      "896\n",
      "number of statuses for user: 1416\n",
      "number of retweets for user: 75\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "retrieving tweets for user TheNickCRBrown\n",
      "821\n",
      "number of statuses for user: 1472\n",
      "number of retweets for user: 145\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "spage error when trying to retrieve RT. continuing\n",
      "tweet access prohibited, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "retrieving tweets for user TheSmithClanNZ\n",
      "676\n",
      "number of statuses for user: 27\n",
      "number of retweets for user: 5\n",
      "retrieving tweets for user wevegot5years\n",
      "671\n",
      "number of statuses for user: 713\n",
      "number of retweets for user: 12\n",
      "retrieving tweets for user RobertGlennieNZ\n",
      "659\n",
      "number of statuses for user: 1995\n",
      "number of retweets for user: 15\n",
      "retrieving tweets for user Larissacomments\n",
      "644\n",
      "number of statuses for user: 555\n",
      "number of retweets for user: 94\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "retrieving tweets for user Head_Weasel\n",
      "550\n",
      "number of statuses for user: 1786\n",
      "number of retweets for user: 21\n",
      "retrieving tweets for user Kezza42456168\n",
      "529\n",
      "number of statuses for user: 347\n",
      "number of retweets for user: 97\n",
      "tweet access prohibited, ignoring\n",
      "tweet has not original status Id for some reason. ignoring.\n",
      "spage error when trying to retrieve RT. continuing\n",
      "retrieving tweets for user letstalkbscs\n",
      "433\n",
      "number of statuses for user: 870\n",
      "number of retweets for user: 121\n",
      "tweet not found, ignoring\n",
      "spage error when trying to retrieve RT. continuing\n",
      "user has been suspended\n",
      "spage error when trying to retrieve RT. continuing\n",
      "retrieving tweets for user baysrealtor\n",
      "312\n",
      "number of statuses for user: 370\n",
      "number of retweets for user: 0\n",
      "retrieving tweets for user RealSmallThings\n",
      "312\n",
      "number of statuses for user: 790\n",
      "number of retweets for user: 1\n",
      "retrieving tweets for user timosh99\n",
      "311\n",
      "number of statuses for user: 355\n",
      "number of retweets for user: 73\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "retrieving tweets for user KiwiDiva\n",
      "238\n",
      "number of statuses for user: 1256\n",
      "number of retweets for user: 166\n",
      "tweet not found, ignoring\n",
      "user has been suspended\n",
      "spage error when trying to retrieve RT. continuing\n",
      "tweet access prohibited, ignoring\n",
      "spage error when trying to retrieve RT. continuing\n",
      "tweet not found, ignoring\n",
      "tweet access prohibited, ignoring\n",
      "tweet access prohibited, ignoring\n",
      "user has been suspended\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet access prohibited, ignoring\n",
      "retrieving tweets for user huanhound\n",
      "72\n",
      "number of statuses for user: 971\n",
      "number of retweets for user: 196\n",
      "status limit almost reached. need to pause for 437\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet access prohibited, ignoring\n",
      "tweet not found, ignoring\n",
      "retrieving tweets for user TheGoodEABeck\n",
      "772\n",
      "number of statuses for user: 14\n",
      "number of retweets for user: 0\n",
      "retrieving tweets for user AndreasHeuserNZ\n",
      "772\n",
      "number of statuses for user: 93\n",
      "number of retweets for user: 7\n",
      "retrieving tweets for user kowhaibird\n",
      "765\n",
      "number of statuses for user: 1985\n",
      "number of retweets for user: 12\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "retrieving tweets for user MJWhitehead\n",
      "753\n",
      "number of statuses for user: 1466\n",
      "number of retweets for user: 68\n",
      "retrieving tweets for user LeDeathmunchkin\n",
      "685\n",
      "number of statuses for user: 945\n",
      "number of retweets for user: 39\n",
      "user has been suspended\n"
     ]
    }
   ],
   "source": [
    "tweet_rt_pairs = get_users_tweets(userids_to_retrieve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try:\n",
    "#     original_tweet = api.get_status(s.quoted_status_id,tweet_mode='extended')\n",
    "# except tweepy.TweepError as tweep_error:\n",
    "#     print(tweep_error)\n",
    "#     te=tweep_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tweet_rt_df = pd.DataFrame(tweet_rt_pairs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_rt_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_rt_df.to_csv(\"../data/housing_peeps_tweets_since2018.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. filter these to a training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tweet_rt_df = pd.read_csv(\"../data/housing_peeps_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_rt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_tweetrow_md(tweetrow):\n",
    "    printmd(\"**TWEET:**\")\n",
    "    printmd(tweetrow['original_text'])\n",
    "    printmd(\"*Retweet:*\")\n",
    "    printmd(tweetrow['retweet_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**TWEET:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "@PaulBMcGill Halfway thru, very nice. Mild mushroom flavour and pleasing consistency a bit like firm tofu or well-cooked squid. I reckon itâ€™d be good in a stir fry with some stronger flavours, but this recipe a good start... https://t.co/SNS3AO3eQE https://t.co/gqZiDfZVl8"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "*Retweet:*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "@PtwoAus https://t.co/TEARNhYuFu https://t.co/vHDcXEzs08"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**TWEET:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "@AklTransport Central Rd to Cardigan St - Stage 2? Please... for safety. Its the most dangerous part with the poor visibility due to high fences and dodgy intersections along the way."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "*Retweet:*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Cannot emphasize this enough, I have had several near misses on this stretch, one resulting in a damaged elbow. I have also seen a few spills. Compared with elsewhere on the NW (including the bit being upgraded) where I have had none. https://t.co/IbomFviXw5"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**TWEET:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "TONIGHT at 6pm: @patrickgowernz will bring to light a significant discovery you need to know about https://t.co/QD3oqf5ZuC https://t.co/10WbYyQDBc"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "*Retweet:*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Full story here: https://t.co/ilvEu4f7Pb https://t.co/vfhrM1p263"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**TWEET:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Victoria University not yet ready to give up the name change fight https://t.co/69jv3fHObp https://t.co/BADbui3yhW"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "*Retweet:*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Disappointing. I'm urging the University to do the right thing here.  It's time to put the name-change idea to one side and instead tap into the huge goodwill students, alumni and the Wellington community have for Vic. Let's work together on the issues that matter.  #StickWithVic https://t.co/e8ZAE0vVQo"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**TWEET:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Hard not to like these pop-up lanes on Tamaki Drive - please value our safety over the storage of vehicles @AklTransport https://t.co/vAksVxbPR3"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "*Retweet:*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The difference 3 days makes - pop ups gone - shared path full of road signs for vehicles. All hail 6 lanes for motor vehicles and trucks @AklTransport ðŸ¤¯ðŸ¤¯ https://t.co/iM1sEOcP5i https://t.co/ECSErpQUZi"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i,row in tweet_rt_df.sample(5).iterrows():\n",
    "    print_tweetrow_md(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housing_tweets = [\n",
    "    t['original_text'] for t in tweet_rt_df.iterrows()\n",
    "for i,row in tweet_rt_df.sample(5).iterrows():\n",
    "    printmd(\"**TWEET:**\")\n",
    "    printmd(row['original_text'])\n",
    "    printmd(\"*Retweet:*\")\n",
    "    printmd(row['retweet_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hmm, most of these tweets aren't related to housing. Maybe that's OK. But what if we applied the same filter we applied to the actual tweets?\n",
    "\n",
    "#### Matching tweets only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/anaconda/envs/tweetenv/lib/python3.7/site-packages/pandas/core/strings.py:1954: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "matching_tweet_vector = tweet_rt_df['original_text'].str.contains('(housing|homeless|RMA)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matching_tweets = tweet_rt_df[matching_tweet_vector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(532, 4)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**TWEET:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Many #LosAngeles motels could be converted to provide short term #housing: https://t.co/isCsz75eZe @KPCC @KPCCrina911 #homelessness #Homeless #news"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "*Retweet:*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Yes! Along with the PSH ordinance, this is a great streamlining bill to speed up provision of housing for homeless Angelenos https://t.co/0d66mYFigp"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**TWEET:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Porirua Growth Strategy is out for public feedback. On our blog, guest poster Tam Holsen finds it detail-rich on greenfield housing development but undercooked on densification or intensification &amp; wonders if her city is missing a trick: https://t.co/gGlFYzsGcw #urbanism #Porirua"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "*Retweet:*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Great to see the YIMBY movement reaching NZ, with pointers to @londonyimby and @brendon_harre https://t.co/BlKJtpPd8g"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**TWEET:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "My book #GoldenGates mixes journalism, history and narrative to show how housing sins of the past led to the housing reality today. Iâ€™ve done a number or excerpts (yet still managed to hold so much back for the book). Here is a piece for Time: https://t.co/4qnBrfU7CQ"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "*Retweet:*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Tune in to the YIMBY Slack tomorrow at 1pm for a live \"Ask me Anything\" with @ConorDougherty. He definitely wants you to ask about the Obama thing.\n",
       "\n",
       "https://t.co/DhmUwhSP6I https://t.co/jqGJql7NfF"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**TWEET:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The 2020 Greater LA Homeless Count results are out today. Here are some of the main takeaways.\n",
       "\n",
       "Learn more about the count and what the numbers mean at https://t.co/1F0UVYPgqi\n",
       "\n",
       "#homelesscount #homelesscountLA #homelesscount2020 https://t.co/CqJRw0eg05"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "*Retweet:*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "I would like to see my taxpayer $ go toward affordable/permanent supportive housing instead of police. #CareNotCops #PeoplesBudgetLA https://t.co/6rzWq1Dzzx"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**TWEET:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Here are slides from my recent talks, \"Housing Element Law for YIMBYs (10 ways to do it better),\" https://t.co/7uC8bXBdlM. This thread sums it up. All stuff that can be done administratively under CA law which requires local govts to plan for regional housing need."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "*Retweet:*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Some quality content for your Thursday. #YIMBY #ThursdayThoughts \n",
       "\n",
       "Thank you @CSElmendorf for sharing your work! https://t.co/U5P3sbtYoz"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i,row in matching_tweets.sample(5).iterrows():\n",
    "    print_tweetrow_md(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can go several directions on this:\n",
    "\n",
    "1. Filter to users who had a tweet matching our filter. Get all their mutual followers. Check mutual follows' RTs; include their housing tweets. Then repeat the process.\n",
    "2. Identify people who were retweeted. Include them in our database, looking for their tweets. Repeat the process with them.\n",
    "\n",
    "I'm going to try the first approach. I think approach (2), simply identifying people whose tweets are topical, might be too broad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housing_tweeters = np.unique(np.concatenate([matching_tweets.rt_author.unique(),(matching_tweets.original_author.unique())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housing_tweeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "api.get_followers_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res=api.friends_ids(screen_names=['curiouskiwicat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_followers(user_id):\n",
    "    user_ids = []\n",
    "    page_count = 0\n",
    "    for userid in tweepy.Cursor(api.followers_ids, id=user_id, count=5000,include_user_entities=False).pages():\n",
    "        print(api.rate_limit_status()['resources']['followers'])\n",
    "        start=time.perf_counter()\n",
    "        page_count += 1\n",
    "        print(f'Getting page {page_count} for followers')\n",
    "        print(userid)\n",
    "        user_ids.extend(userid)\n",
    "        end= time.perf_counter()\n",
    "        #iterate through a maximum of 400 users per second\n",
    "        duration=end-start\n",
    "        if(duration<1):\n",
    "            time.sleep(1-duration)\n",
    "    return user_ids\n",
    "\n",
    "\n",
    "def get_friends(user_id):\n",
    "    user_ids = []\n",
    "    page_count = 0\n",
    "    for userid in tweepy.Cursor(api.friends_ids, id=user_id, count=5000,include_user_entities=False).pages():\n",
    "        print(api.rate_limit_status()['resources']['followers'])\n",
    "        page_count += 1\n",
    "        print(userid)\n",
    "        print(f'Getting page {page_count} for friends')\n",
    "        user_ids.extend(userid)\n",
    "    return user_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rls=api.rate_limit_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rls['resources']['followers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rls['resources']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users_of_interest = housing_tweeters\n",
    "new_users_of_interest=[]\n",
    "for i,u in enumerate(users_of_interest):\n",
    "    print(f\"{i} of {len(users_of_interest)}\")\n",
    "    #followers = get_followers(u)\n",
    "    friends = get_friends(u)\n",
    "    mutuals = set(friends).intersection(followers)\n",
    "    new_users_of_interest = new_users_of_interest + list(mutuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not going to work because we get rate limited. I'm only able to do as many as 15 follower and friend listings before I get rate limited.\n",
    "\n",
    "#### Approach 2\n",
    "\n",
    "I could instead just look at the second approach - just getting people who were RT'd by the original user. Ideally we look at ALL those who were retweeted, not just the ones talking about housing. However, because we are rate limited, it is probably better to limit to just the retweets about housing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "next_pass_of_users=matching_tweets.original_author.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['matpottinger', 'radionz', 'Royal_Greenwich', 'TheMurkyDepths',\n",
       "       'AbundantHomeLDN', 'PeteApps', 'LabourHousing', 'russellcurtis',\n",
       "       'GoodwinMJ', 'SkyNews', 'RobertKwolek', 'tomcopley', 'AntBreach',\n",
       "       'winkybiker', 'BDonline', 'CentreforCities', 'tomravenscroft',\n",
       "       'geographyjim', 'Apex_airspace', 'Leo_Pollak', 'tperry518',\n",
       "       'CamdenCouncil', 'wfcouncil', 'AFL_tweet', 'stockwool',\n",
       "       'terraplanner', 'WalnutParkLA', 'UrbanEnviroCA', 'louismirante',\n",
       "       'CarterRubin', 'StanleyMJohnson', 'esgarciaa', 'graysonapeters',\n",
       "       'Planning4LA', 'AyannaPressley', 'beyondchron', 'LeftistConnor',\n",
       "       'AbundantHousing', 'nkburns3', 'CSElmendorf', 'Up4Growth',\n",
       "       'AmyDoraMD', 'anthonydedousis', 'SophiaBush', 'SDGaction',\n",
       "       'LosAngelesFwd', 'AOC', 'SonjaTrauss', 'AbundantHomesMA',\n",
       "       'Scott_Wiener', 'ahvancouver', 'mlevinreports', 'CurbedLA',\n",
       "       'BarackObama', 'MikeBoninLA', 'SenGonzalez_33', 'DavidZahniser',\n",
       "       'DotKohlhaas', 'ShaneDPhillips', 'dillonliam', 'anniefryman',\n",
       "       'CamnerLeonora', 'MayorOfLA', 'jasonislas', 'cayimby', 'elpaavo',\n",
       "       'calwatch', 'markvalli', 'BrentGaisford', 'UrbanizeLA',\n",
       "       'AlexFischCC', 'Ben_J_Winter', 'chrissmithus', 'HousingOC',\n",
       "       'Dan_Rinzler', 'LAist', 'katherineeinst', 'kimberlysfox',\n",
       "       'SierraClubSEA', 'naehomelessness', 'expolineledger',\n",
       "       'MattRegan10', 'latimesopinion', 'jondearing', 'RobertGarciaLB',\n",
       "       'VamonosLA', 'LATpoliticsCA', 'randlev', 'latimes',\n",
       "       'CityAttorneyLA', 'hanlonbt', 'Cupertino4All', 'aceckhouse',\n",
       "       'kookie13', 'dylan_casey12', 'theoverheadwire', 'carla_org',\n",
       "       'IDoTheThinking', 'about_dave', 'CarterLavin', 'KartikGadaATOM',\n",
       "       'AGBecerra', 'sashaperigo', 'alfred_twu', 'KrampusSnail',\n",
       "       '43rdparallel', 'cafedujord', 'DaytonPubPolicy', 'NancySkinnerCA',\n",
       "       'JalbyMD', 'mateosfo', 'kimmaicutler', 'asastrout', 'berkeleyside',\n",
       "       'AaronPeskin', 'BenRossTransit', 'TribTowerViews', 'hlc_sanmateo',\n",
       "       'marinforgrowth', 'SVatHome', 'FactChecker23', 'pushtheneedle',\n",
       "       'agcotter', 'wendy_waters', 'jfatkey', 'HenryKraemer',\n",
       "       'fabulavancouver', 'StreetsblogMASS', 'cbcnewsbc', 'laureljeanine',\n",
       "       'fumano', 'Ben_coli', 'j_mcelroy', 'VanCourierNews', 'JenStDen',\n",
       "       'LetsFixHousing', 'ShaunaSylvester', 'alexbozikovic',\n",
       "       'LondonBreed', 'TheresaMcManus', 'kenpaquette', 'Renee1130',\n",
       "       'VaughnPalmer', 'MSPyimby', 'VKNDP', 'StewartPrest', 'LAHomeless',\n",
       "       'Acosta', 'realDonaldTrump', 'DavidChiu', 'dagarciajr',\n",
       "       'MarisaKendall', 'lae_sf', 'PhilTing', 'CirbReport', 'adrianfine',\n",
       "       'TECollab', 'LarsonMP', 'JulianCastro', 'loridroste', 'jdawsey1',\n",
       "       'AndrewFeinberg', 'NZcivildefence', 'matty_prasad',\n",
       "       'RosieMicklegate', 'TheAtlantic', 'scottlincicome', 'dhmorris',\n",
       "       'RMarchNZ', 'barbarikkizzle', 'FrankMcRae', 'fascismdad',\n",
       "       'kilbrniesanders', 'BenRoss_AKL', 'ColourMeFiji', 'SuzanneRobins1',\n",
       "       'DallasRogers101', 'cjsbishop', 'HomeBuyerClub', 'chamfy',\n",
       "       'CityLab', 'NicolaWillisMP', 'henrycooke', 'luke_wijohn',\n",
       "       'YoungGreensNZ', 'Public_Citizen', 'NZStuffPolitics', 'cjhamblin',\n",
       "       'brendon_harre', 'DrMichaelReid', 'HelenClarkNZ', 'Orla_Hegarty',\n",
       "       'TeriONeillNZ', 'CAgovernor', 'five15design', 'kirsty_johnston',\n",
       "       'NZAllison', 'MarkThomasNZ', 'MaramaDavidson', 'LifewiseNZ',\n",
       "       'PlatformTrust', 'SalvationArmyNZ', 'lgnz', 'DeItaOne',\n",
       "       'marcdaalder', 'econhedge', 'ecomanda', 'kiwieconomics',\n",
       "       'iwik8816', 'kumararepublic', 'EricCrampton', 'NewsroomNZ',\n",
       "       'Birdyword', 'geoffsimmonz', 'adam_tooze', 'NZStuff', 'kiangoh',\n",
       "       'bbqr0ast', 'bradlander', 'kentslundberg', 'secvalve', 'reidwicks',\n",
       "       'DrCameronMurray', 'MikeLindblom', 'NzHomeless', 'coughlthom',\n",
       "       'dbseymour', 'JeneeTibshraeny', 'golrizghahraman', 'A_G_Hawkins',\n",
       "       'TheSpinoffTV', 'laura_oc_rapira', 'robellcampbin', 'iain_white',\n",
       "       'simonbwilson', 'UNGeneva', 'nzlabour', 'jaackiepaul',\n",
       "       'urbanadvisory', 'leilanifarha', 'HUDgovtnz', 'regstud',\n",
       "       'BrentToderian', 'KaysHistory', 'moturesearch', 'rnz_news',\n",
       "       'JamesBerghan', 'StreetsblogUSA', 'ninetonoon', 'buildbetternz',\n",
       "       'Phil_PJA', 'GoodSenseMktg', 'DarrenDavis10', 'NextCityOrg',\n",
       "       'NZGBC', 'nzherald', 'MFarmer_Resi', 'CheckpointRNZ', 'CEEexeter',\n",
       "       'BRANZlive', 'via_arch', 'PassiveHouseBB', 'ansellundberg',\n",
       "       'maustermuhle', 'dianeyentel', 'yimbyaction', 'ericpanzer',\n",
       "       'OpenNYForAll', 'BuffyWicks', 'SactownTalks', 'gisellemarie',\n",
       "       'NeverSassyLaura', 'ConorDougherty', 'emilymbadger',\n",
       "       'Bobakkabob37', 'wafoli', 'YIMBYTempe', 'kristoncapps',\n",
       "       'thecliffbar', 'NPHANC', 'TernerHousing', 'jenny_schuetz',\n",
       "       'davidcying', 'Pass3PsCA', 'willrk787', 'pydems', 'SenWarren',\n",
       "       'jamilnkhan', 'RepDennyHeck', 'Chris_Wood0', 'MKorevaar93',\n",
       "       'PrincesFound', 'MattWGriffith', 'CapX', 'sbcrosscountry',\n",
       "       'TalkWelly', 'sfchronicle', 'LSEInequalities', 'yimbyalliance',\n",
       "       'trustforlondon', 'iealondon', 'Jphsmith', 'BristolYIMBY',\n",
       "       'HistoricEngland', 'homelessimpact', 'ThinkhouseInfo',\n",
       "       'housingevidence', 'rtpiknowledge', 'GreaterAKL', 'HomelessDay',\n",
       "       'ryanmearns', 'sharkpatu', 'Jay_Pitter', 'PhilTwyford',\n",
       "       'HousingFirstNZ', 'Stats_NZ', 'ChChMethodistMn', 'nzinitiative',\n",
       "       'NewshubNationNZ', '_chloeswarbrick', 'NewshubNZ', 'NewstalkZB',\n",
       "       'jacindaardern', 'NZStuffBusiness', 'nzlistener', 'jamespeshaw',\n",
       "       'NZGreens', 'phil_goff', 'urbanizationist', 'MBIEgovtnz'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_pass_of_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "right, now we iterate through them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieving tweets for user matpottinger\n",
      "900\n",
      "number of statuses for user: 684\n",
      "number of retweets for user: 18\n",
      "retrieving tweets for user radionz\n",
      "882\n",
      "number of statuses for user: 1712\n",
      "number of retweets for user: 101\n",
      "retrieving tweets for user Royal_Greenwich\n",
      "781\n",
      "number of statuses for user: 1758\n",
      "number of retweets for user: 38\n",
      "retrieving tweets for user TheMurkyDepths\n",
      "743\n",
      "number of statuses for user: 1199\n",
      "number of retweets for user: 231\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "spage error when trying to retrieve RT. continuing\n",
      "spage error when trying to retrieve RT. continuing\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "retrieving tweets for user AbundantHomeLDN\n",
      "512\n",
      "number of statuses for user: 973\n",
      "number of retweets for user: 304\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "spage error when trying to retrieve RT. continuing\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "retrieving tweets for user PeteApps\n",
      "208\n",
      "number of statuses for user: 1611\n",
      "number of retweets for user: 107\n",
      "tweet not found, ignoring\n",
      "user has been suspended\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "retrieving tweets for user LabourHousing\n",
      "101\n",
      "number of statuses for user: 173\n",
      "number of retweets for user: 23\n",
      "retrieving tweets for user russellcurtis\n",
      "78\n",
      "number of statuses for user: 1874\n",
      "number of retweets for user: 59\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "retrieving tweets for user GoodwinMJ\n",
      "19\n",
      "number of statuses for user: 1734\n",
      "number of retweets for user: 108\n",
      "tweet not found, ignoring\n",
      "status limit almost reached. need to pause for 391\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "retrieving tweets for user SkyNews\n",
      "807\n",
      "number of statuses for user: 1943\n",
      "number of retweets for user: 0\n",
      "retrieving tweets for user RobertKwolek\n",
      "807\n",
      "number of statuses for user: 1561\n",
      "number of retweets for user: 68\n",
      "tweet access prohibited, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "retrieving tweets for user tomcopley\n",
      "739\n",
      "number of statuses for user: 1091\n",
      "number of retweets for user: 219\n",
      "tweet access prohibited, ignoring\n",
      "spage error when trying to retrieve RT. continuing\n",
      "retrieving tweets for user AntBreach\n",
      "520\n",
      "number of statuses for user: 1569\n",
      "number of retweets for user: 185\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet access prohibited, ignoring\n",
      "tweet has not original status Id for some reason. ignoring.\n",
      "retrieving tweets for user winkybiker\n",
      "336\n",
      "number of statuses for user: 1903\n",
      "number of retweets for user: 43\n",
      "tweet not found, ignoring\n",
      "retrieving tweets for user BDonline\n",
      "293\n",
      "number of statuses for user: 1721\n",
      "number of retweets for user: 6\n",
      "retrieving tweets for user CentreforCities\n",
      "287\n",
      "number of statuses for user: 1692\n",
      "number of retweets for user: 112\n",
      "retrieving tweets for user tomravenscroft\n",
      "175\n",
      "number of statuses for user: 1485\n",
      "number of retweets for user: 75\n",
      "tweet not found, ignoring\n",
      "retrieving tweets for user geographyjim\n",
      "100\n",
      "number of statuses for user: 1269\n",
      "number of retweets for user: 121\n",
      "tweet not found, ignoring\n",
      "status limit almost reached. need to pause for 379\n",
      "tweet has not original status Id for some reason. ignoring.\n",
      "tweet has not original status Id for some reason. ignoring.\n",
      "tweet has not original status Id for some reason. ignoring.\n",
      "tweet has not original status Id for some reason. ignoring.\n",
      "tweet has not original status Id for some reason. ignoring.\n",
      "retrieving tweets for user Apex_airspace\n",
      "880\n",
      "number of statuses for user: 317\n",
      "number of retweets for user: 47\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet has not original status Id for some reason. ignoring.\n",
      "retrieving tweets for user Leo_Pollak\n",
      "834\n",
      "number of statuses for user: 609\n",
      "number of retweets for user: 109\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet access prohibited, ignoring\n",
      "tweet not found, ignoring\n",
      "retrieving tweets for user tperry518\n",
      "725\n",
      "number of statuses for user: 733\n",
      "number of retweets for user: 53\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "retrieving tweets for user CamdenCouncil\n",
      "672\n",
      "number of statuses for user: 1549\n",
      "number of retweets for user: 63\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "retrieving tweets for user wfcouncil\n",
      "609\n",
      "number of statuses for user: 1891\n",
      "number of retweets for user: 77\n",
      "tweet not found, ignoring\n",
      "retrieving tweets for user AFL_tweet\n",
      "532\n",
      "number of statuses for user: 235\n",
      "number of retweets for user: 8\n",
      "retrieving tweets for user stockwool\n",
      "524\n",
      "number of statuses for user: 242\n",
      "number of retweets for user: 8\n",
      "retrieving tweets for user terraplanner\n",
      "516\n",
      "number of statuses for user: 1829\n",
      "number of retweets for user: 123\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet has not original status Id for some reason. ignoring.\n",
      "retrieving tweets for user WalnutParkLA\n",
      "394\n",
      "number of statuses for user: 13\n",
      "number of retweets for user: 6\n",
      "retrieving tweets for user UrbanEnviroCA\n",
      "388\n",
      "number of statuses for user: 570\n",
      "number of retweets for user: 124\n",
      "tweet has not original status Id for some reason. ignoring.\n",
      "tweet not found, ignoring\n",
      "retrieving tweets for user louismirante\n",
      "265\n",
      "number of statuses for user: 1433\n",
      "number of retweets for user: 120\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "retrieving tweets for user CarterRubin\n",
      "145\n",
      "number of statuses for user: 787\n",
      "number of retweets for user: 155\n",
      "tweet not found, ignoring\n",
      "spage error when trying to retrieve RT. continuing\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "status limit almost reached. need to pause for 402\n",
      "retrieving tweets for user StanleyMJohnson\n",
      "886\n",
      "number of statuses for user: 647\n",
      "number of retweets for user: 21\n",
      "user has been suspended\n",
      "retrieving tweets for user esgarciaa\n",
      "865\n",
      "number of statuses for user: 340\n",
      "number of retweets for user: 64\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "retrieving tweets for user graysonapeters\n",
      "801\n",
      "number of statuses for user: 411\n",
      "number of retweets for user: 68\n",
      "tweet has not original status Id for some reason. ignoring.\n",
      "tweet has not original status Id for some reason. ignoring.\n",
      "tweet has not original status Id for some reason. ignoring.\n",
      "retrieving tweets for user Planning4LA\n",
      "736\n",
      "number of statuses for user: 1182\n",
      "number of retweets for user: 57\n",
      "tweet not found, ignoring\n",
      "retrieving tweets for user AyannaPressley\n",
      "679\n",
      "number of statuses for user: 1027\n",
      "number of retweets for user: 236\n",
      "tweet has not original status Id for some reason. ignoring.\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet access prohibited, ignoring\n",
      "tweet access prohibited, ignoring\n",
      "retrieving tweets for user beyondchron\n",
      "444\n",
      "number of statuses for user: 1988\n",
      "number of retweets for user: 319\n",
      "tweet has not original status Id for some reason. ignoring.\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "retrieving tweets for user LeftistConnor\n",
      "126\n",
      "number of statuses for user: 1812\n",
      "number of retweets for user: 219\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "status limit almost reached. need to pause for 436\n",
      "spage error when trying to retrieve RT. continuing\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "retrieving tweets for user AbundantHousing\n",
      "803\n",
      "number of statuses for user: 1142\n",
      "number of retweets for user: 251\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet has not original status Id for some reason. ignoring.\n",
      "tweet has not original status Id for some reason. ignoring.\n",
      "tweet has not original status Id for some reason. ignoring.\n",
      "tweet has not original status Id for some reason. ignoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet has not original status Id for some reason. ignoring.\n",
      "tweet has not original status Id for some reason. ignoring.\n",
      "tweet has not original status Id for some reason. ignoring.\n",
      "tweet has not original status Id for some reason. ignoring.\n",
      "retrieving tweets for user nkburns3\n",
      "560\n",
      "number of statuses for user: 1756\n",
      "number of retweets for user: 320\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet has not original status Id for some reason. ignoring.\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet has not original status Id for some reason. ignoring.\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet has not original status Id for some reason. ignoring.\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet access prohibited, ignoring\n",
      "tweet not found, ignoring\n",
      "retrieving tweets for user CSElmendorf\n",
      "243\n",
      "number of statuses for user: 773\n",
      "number of retweets for user: 75\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "retrieving tweets for user Up4Growth\n",
      "168\n",
      "number of statuses for user: 953\n",
      "number of retweets for user: 112\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "retrieving tweets for user AmyDoraMD\n",
      "56\n",
      "number of statuses for user: 114\n",
      "number of retweets for user: 18\n",
      "retrieving tweets for user anthonydedousis\n",
      "38\n",
      "number of statuses for user: 146\n",
      "number of retweets for user: 10\n",
      "retrieving tweets for user SophiaBush\n",
      "28\n",
      "number of statuses for user: 435\n",
      "number of retweets for user: 194\n",
      "status limit almost reached. need to pause for 454\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet access prohibited, ignoring\n",
      "tweet not found, ignoring\n",
      "retrieving tweets for user SDGaction\n",
      "730\n",
      "number of statuses for user: 1291\n",
      "number of retweets for user: 174\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet access prohibited, ignoring\n",
      "retrieving tweets for user LosAngelesFwd\n",
      "556\n",
      "number of statuses for user: 467\n",
      "number of retweets for user: 97\n",
      "tweet not found, ignoring\n",
      "tweet access prohibited, ignoring\n",
      "tweet not found, ignoring\n",
      "retrieving tweets for user AOC\n",
      "459\n",
      "number of statuses for user: 1185\n",
      "number of retweets for user: 539\n",
      "tweet has not original status Id for some reason. ignoring.\n",
      "tweet not found, ignoring\n",
      "tweet access prohibited, ignoring\n",
      "tweet not found, ignoring\n",
      "tweet not found, ignoring\n",
      "error while handling exception. passing back exception.\n"
     ]
    }
   ],
   "source": [
    "user_tweets2 = get_users_tweets(next_pass_of_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'user_tweets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-6659bdd97054>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtweet_rt_df_l2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_tweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'user_tweets' is not defined"
     ]
    }
   ],
   "source": [
    "tweet_rt_df_l2 = pd.DataFrame(user_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matching_tweet_vector = tweet_rt_df['original_text'].str.contains('(housing|homeless|RMA)')\n",
    "matching_tweets = tweet_rt_df[matching_tweet_vector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,row in matching_tweets.sample(5).iterrows():\n",
    "    print_tweetrow_md(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_rt_df = pd.read_csv(\"../data/housing_peeps_tweets.csv\")\n",
    "\n",
    "def get_housing_tweets(full_tweet_list):\n",
    "    matching_tweet_vector = full_tweet_list['original_text'].str.contains('(housing|homeless|RMA)')\n",
    "    matching_tweets = full_tweet_list[matching_tweet_vector]\n",
    "    return(matching_tweets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_set=pd.concat([get_housing_tweets(tweet_rt_df),get_housing_tweets(tweet_rt_df_l2)]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_set.to_csv(\"../data/housing_peeps_tweets_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_row_to_plaintext(row):\n",
    "    return(row['original_text'] + \"\\nRT: \\n\" +  row['retweet_text'] + \"\\n<|endoftext|>\\n\")\n",
    "plaintext_vals=full_set.apply(convert_row_to_plaintext,1)\n",
    "plain_text_out = \"\\n\".join(plaintext_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(plain_text_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raise Exception(\"should trim out the links, probably\")\n",
    "with open(\"../data/housing_fulltext_plain.txt\",'w') as text_file:\n",
    "    print(plain_text_out,file=text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tweetenv]",
   "language": "python",
   "name": "conda-env-tweetenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
